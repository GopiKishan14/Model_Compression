{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gopi/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "##### import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading MNIST Dataset\n",
    "\"\"\"\n",
    "\n",
    "def load_mnist():\n",
    "    (x_train,y_train), (x_test,y_test) = mnist.load_data()\n",
    "    \n",
    "    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
    "\n",
    "    y_train = to_categorical(y_train.astype('float32'))\n",
    "    y_test = to_categorical(y_test.astype('float32'))\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initial CNN Model\n",
    "\"\"\"\n",
    "def build_simple_model():\n",
    "    inputs = layers.Input(shape=(28,28,1))\n",
    "    x = layers.Conv2D(32, kernel_size=(3,3), activation='relu', name=\"Conv1\")(inputs)\n",
    "    x = layers.Conv2D(64, kernel_size=(3,3), activation='relu', name=\"Conv2\")(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='MaxPool')(x)\n",
    "    x = layers.Dropout(rate=0.25, name='Dropout1')(x)\n",
    "    \n",
    "    x = layers.Flatten(name='Flat')(x)\n",
    "    x = layers.Dense(128, activation='relu', name='FC1')(x)\n",
    "    x = layers.Dropout(rate=0.5, name='Dropout2')(x)\n",
    "\n",
    "    \n",
    "    x = layers.Dense(10, name='logits')(x)\n",
    "    preds = layers.Activation('softmax', name='Softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=preds)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "MaxPool (MaxPooling2D)       (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Dropout1 (Dropout)           (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flat (Flatten)               (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "Dropout2 (Dropout)           (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "logits (Dense)               (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "Softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_simple_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1536/60000 [..............................] - ETA: 18:16 - loss: 2.1586 - acc: 0.3014"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_mnist()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=512)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 545us/step\n",
      "Test Loss: 0.03430916118031746\n",
      "Test Accuracy: 0.9884\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Softmax with Temperature\n",
    "\"\"\"\n",
    "\n",
    "def softmax_with_temperature(logits, temperature=1):\n",
    "    logits = logits / temperature\n",
    "    return np.exp(logits) / np.sum(np.exp(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prev_softmax = Model(inputs=model.input, outputs=model.get_layer(\"logits\").output)\n",
    "model_logits = model_prev_softmax.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsoftened_train_prob = softmax_with_temperature(model_logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mnist_image(img_arr):\n",
    "  plt.imshow(img_arr.reshape([28, 28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09eaff3128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mnist_image(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsoftened probabilities:  [1.2512286e-16 1.3515365e-15 3.9405431e-16 1.3119422e-10 1.9544782e-16\n",
      " 6.8480372e-09 2.6516942e-14 1.3813276e-14 3.4258627e-14 1.3671341e-13]\n",
      "\n",
      "Prediction based on unsoftened probability:  5\n"
     ]
    }
   ],
   "source": [
    "print(\"Unsoftened probabilities: \", unsoftened_train_prob[0])\n",
    "print()\n",
    "print(\"Prediction based on unsoftened probability: \", np.argmax(unsoftened_train_prob[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 4\n",
    "softened_train_prob = softmax_with_temperature(model_logits, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softened probabilities:  [5.1590593e-08 9.3528350e-08 6.8726678e-08 1.6508782e-06 5.7675859e-08\n",
      " 4.4373928e-06 1.9684174e-07 1.6722858e-07 2.0985958e-07 2.9661228e-07]\n",
      "\n",
      "Prediction based on Softened probability:  5\n"
     ]
    }
   ],
   "source": [
    "print(\"Softened probabilities: \", softened_train_prob[0])\n",
    "print()\n",
    "print(\"Prediction based on Softened probability: \", np.argmax(softened_train_prob[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09ea6cb780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mnist_image(x_train[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softened probabilities:  [2.1526787e-07 6.7508154e-08 9.8014007e-06 3.4076433e-07 6.0945318e-08\n",
      " 8.7571721e-08 3.4415706e-08 9.5475548e-07 3.2501762e-07 9.4076306e-08]\n",
      "\n",
      "Prediction based on softened probability:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Softened probabilities: \", softened_train_prob[16])\n",
    "print()\n",
    "print(\"Prediction based on softened probability: \", np.argmax(softened_train_prob[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_small_model():\n",
    "    inputs = layers.Input(shape=(28, 28, 1))\n",
    "    x = layers.Flatten()(inputs)\n",
    "    x = layers.Dense(128, activation='relu', name='FC1')(x)\n",
    "    x = layers.Dense(128, activation='relu', name='FC2')(x)\n",
    "    x = layers.Dense(10, name='logits')(x)\n",
    "    preds = layers.Activation('softmax', name='Softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=preds)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "logits (Dense)               (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "Softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "small_model = build_small_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0371 - acc: 0.9892\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0318 - acc: 0.9911\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0285 - acc: 0.9925\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0242 - acc: 0.9941\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0201 - acc: 0.9949\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0203 - acc: 0.9947\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0165 - acc: 0.9961\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0131 - acc: 0.9974\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0121 - acc: 0.9974\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0099 - acc: 0.9981\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0083 - acc: 0.9987\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0084 - acc: 0.9984\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0084 - acc: 0.9983\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0059 - acc: 0.9993\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0047 - acc: 0.9996\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0043 - acc: 0.9996\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0033 - acc: 0.9997\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0039 - acc: 0.9995\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0032 - acc: 0.9997\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0026 - acc: 0.9999\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0029 - acc: 0.9993\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0333 - acc: 0.9893\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0140 - acc: 0.9951\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0061 - acc: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f09e85f2128>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model.fit(x_train, y_train, epochs=30, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 29us/step\n",
      "Test Loss: 0.10984879909294341\n",
      "Test Accuracy: 0.9758\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = small_model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "logits (Dense)               (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "Softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "New Model Summary\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "logits (Dense)               (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "Temperature (Lambda)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "Softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Knowledge Transfering\n",
    "\"\"\"\n",
    "\n",
    "new_small_model = build_small_model()\n",
    "logits = new_small_model.get_layer('logits').output\n",
    "logits = layers.Lambda(lambda x: x / temperature, name='Temperature')(logits)\n",
    "preds = layers.Activation('softmax', name='Softmax')(logits)\n",
    "  \n",
    "new_small_model = Model(inputs=new_small_model.input, outputs=preds)\n",
    "print(\"New Model Summary\")\n",
    "new_small_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1.9514e-05 - acc: 0.7014\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.2487e-05 - acc: 0.9153\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.1951e-05 - acc: 0.9390\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.1697e-05 - acc: 0.9518\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.1544e-05 - acc: 0.9609\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.1453e-05 - acc: 0.9666\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.1389e-05 - acc: 0.9709\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.1344e-05 - acc: 0.9746\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.1312e-05 - acc: 0.9765\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.1290e-05 - acc: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f09e8579fd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_small_model.compile(optimizer=Adam(lr=0.03), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "new_small_model.fit(x_train, softened_train_prob, epochs=10, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 36us/step\n",
      "Test Loss: 0.3040420033931732\n",
      "Test Accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = new_small_model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
